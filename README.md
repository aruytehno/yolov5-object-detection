## Распределенная система видео аналитики

## Установка

1. Установите Docker и Docker Compose.
2. Соберите и запустите проект:
   ```bash
   docker-compose up --build
   ```


Этот проект представляет собой распределенную систему видеоаналитики, которая позволяет обрабатывать видеопотоки, проводить инференс с использованием модели YOLO для детекции объектов и управлять выполнением сценариев с помощью оркестратора. Вот основные компоненты и их функционал:

### Основные компоненты проекта

1. **Runner ()**  
   - Запускает обработку видеопотока из локального видео или потокового источника.
   - Обрабатывает каждый кадр, преобразовывая его (например, изменяет цветовую схему) и отправляет на сервер инференса.
   - Получает и выводит результаты предсказания от сервиса инференса для каждого кадра.
   - Позволяет добавить задержку (например, для контроля нагрузки).

2. **Inference ()**  
   - Является сервисом инференса, выполняющим предсказания с помощью модели YOLO.
   - Принимает изображения от `Runner`, обрабатывает их и возвращает результаты детекции.
   - Включает функцию `health_check` для проверки работоспособности своих зависимых компонентов (например, Runner и Orchestrator).

3. **Orchestrator ()**  
   - Управляет состоянием всей системы с помощью конечного автомата состояний (state machine).
   - Инициализирует, активирует, выключает и отслеживает текущие состояния, что позволяет точно контролировать выполнение сценария.
   - Предусмотрены состояния и переходы, такие как `init_startup`, `active`, `init_shutdown`, и другие, что помогает реализовать процессы запуска и завершения.

4. **API сервер ()**  
   - Сервис взаимодействия с пользователем, обеспечивающий управление системой и мониторинг.
   - Позволяет:
     - Получить информацию о текущем состоянии сценария (GET `/scenario/{id}`).
     - Изменить состояние системы, запустив или остановив выполнение (POST `/scenario/{id}/state`).
   - Содержит метод `health_check` для проверки доступности API.

### Основной поток работы

1. **Запуск сценария**: Пользователь отправляет запрос на изменение состояния сценария через API. Оркестратор меняет состояние системы в соответствии с запросом.
2. **Обработка видео**: `Runner` захватывает видеопоток, предварительно обрабатывает кадры и отправляет их на сервер инференса для предсказаний.
3. **Инференс**: `Inference` принимает кадры, выполняет детекцию объектов с помощью YOLO и возвращает результаты `Runner`.
4. **Контроль системы**: Оркестратор следит за состоянием системы, управляя переходами между состояниями, такими как запуск, активная обработка, и завершение работы.
5. **Мониторинг**: API предоставляет пользователям возможность получить актуальное состояние и информацию о системе.

### Применение

Данный проект может применяться для автоматического анализа видеопотоков, например, для безопасности, распознавания объектов или мониторинга активности. Распределенная архитектура и четкое разграничение ролей компонентов делают его устойчивым к нагрузкам и легко расширяемым.



# ТЗ Video Analytics Project:

### uml
- https://habr.com/ru/companies/alfa/articles/740518/

## api
- **GET** - информация о сценарии по его ID (текущий статус \ параметры работы \ ...)
- **POST** - изменение состояния стейт-машины (запуск \ остановка \ ...)
### docs
- https://fastapi.tiangolo.com/
- https://github.com/aio-libs/aiokafka
### healthcheck
- https://habr.com/ru/companies/nixys/articles/544288/
- https://github.com/peter-evans/docker-compose-healthcheck

## orchestrator (orchestration \ choreography \ mix \ ...)
- **чтение события (команды)** - получение запроса от api
- **контроль состояния** - сохранение \ изменение
- **выполнение действия** - управление runner`ом
### state machine
- **init_startup** - инициализация запуска
- **in_startup_processing** - промежуточное состояние, олицетворяющее процесс запуска
- **init_shutdown** - инициализация остановки
- **in_shutdown_processing** - промежуточное состояние, олицетворяющее процесс остановки
- **active** - активная состояние \ работа 
- **inactive** - выключенное состояние

## runner
- **чтение кадра** - живой поток (rtsp \ onvif \ ...) и\или заготовленное локальное видео
- **препроцессинг (optional)** - подготовка полученного кадра к отправке (BGR2RGB \ resize \ ...)
- **отправка кадра** - отправка кадра в сервис предсказания
- **получение результата** - чтение результатов с предсказаниями
- **постпроцессинг (optional)** - подготовка результата к обработке

## inference
- **чтение кадра** - получение кадра из очереди
- **предсказание** - inference
- **отправка результатов** - возврат результатов в runner
### docs
- https://github.com/ultralytics/ultralytics
- https://habr.com/ru/articles/717890/ (optional)
- https://docs.ultralytics.com/guides/triton-inference-server/ (optional)
